{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import shutil\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "os.chdir('/Users/tanyatsui/Documents/01_Projects/housingEmissions')\n",
    "from data_processing._common.params_manager import ParamsManager\n",
    "from data_processing._common.query_runner import QueryRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBS Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBSDataProcessor(): \n",
    "    def __init__(self):\n",
    "        self.columns_of_interest = [\n",
    "            'gwb_code_10', 'regio', 'gm_naam', 'recs', \n",
    "            'a_inw', 'a_hh', 'a_woning', 'g_ele', 'g_gas', 'p_stadsv'\n",
    "        ]\n",
    "    \n",
    "    def run(self): \n",
    "        self.read_data_2012()\n",
    "        self.change_column_names_2012()\n",
    "        self.add_missing_columns_2012()\n",
    "        # TODO: self.add_woz_columns_pre2020()\n",
    "        self.combine_data()\n",
    "        self.format_data(columns_list=['g_ele', 'g_gas', 'p_stadsv'])\n",
    "        self.save_data()\n",
    "\n",
    "    def read_data_2012(self):\n",
    "        dtype_dict = {\n",
    "            'WK_CODE': str, 'BU_CODE': str, \n",
    "            'Code_10_pos12': str, 'GWB_CODE12': str, \n",
    "            'GM_CODE': str\n",
    "        }\n",
    "        df_file_2012 = pd.read_excel('data/raw/cbs/kwb-2012.xls', converters=dtype_dict)\n",
    "        self.data_2012 = df_file_2012\n",
    "\n",
    "    def change_column_names_2012(self): \n",
    "        column_conversion_dict = {\n",
    "            'GWB_NAAM12_60POS': 'regio',\n",
    "            'GEM_NAAM': 'gm_naam', \n",
    "            'AANT_INW': 'a_inw', \n",
    "            'AANTAL_HH': 'a_hh',\n",
    "            'WONINGEN': 'a_woning', \n",
    "            'P_ELEK_TOT': 'g_ele',\n",
    "            'P_GAS_TOT': 'g_gas', \n",
    "            'P_STADVERW': 'p_stadsv'\n",
    "        }\n",
    "        self.data_2012.rename(columns=column_conversion_dict, inplace=True)\n",
    "\n",
    "    def add_missing_columns_2012(self): \n",
    "        self._add_recs()\n",
    "        self._add_gwb_code_10()\n",
    "    \n",
    "    def _add_recs(self): \n",
    "        def _lambda_make_recs_code(row): \n",
    "            recs_dict = {\n",
    "                'B': 'BU', 'W': 'WK', 'G': 'GM', 'N': 'NL'\n",
    "            }\n",
    "            return recs_dict[row.RECS]\n",
    "        def _lambda_make_recs(row): \n",
    "            recs_dict = {\n",
    "                'B': 'Buurt', 'W': 'Wijk', 'G': 'Gemeente', 'N': 'Land'\n",
    "            }\n",
    "            return recs_dict[row.RECS]\n",
    "        self.data_2012['recs_code'] = self.data_2012.apply(lambda row: _lambda_make_recs_code(row), axis=1)\n",
    "        self.data_2012['recs'] = self.data_2012.apply(lambda row: _lambda_make_recs(row), axis=1)\n",
    "\n",
    "    def _add_gwb_code_10(self):\n",
    "        def _lambda_make_gwb_code_10(row): \n",
    "            if pd.isna(row.WK_CODE): \n",
    "                row.WK_CODE = ''\n",
    "            if pd.isna(row.BU_CODE):\n",
    "                row.BU_CODE = ''\n",
    "            return f'{row.recs_code}{row.GM_CODE}{row.WK_CODE}{row.BU_CODE}'\n",
    "        self.data_2012['gwb_code_10'] = self.data_2012.apply(lambda row: _lambda_make_gwb_code_10(row), axis=1)\n",
    "\n",
    "    def add_woz_columns_pre2020(self):\n",
    "        None\n",
    "        # add missing woz columns for pre-2020 data \n",
    "    \n",
    "    def combine_data(self): \n",
    "        df_list = []\n",
    "        self.data_2012 = self.data_2012[self.columns_of_interest]\n",
    "        self.data_2012['year'] = 2012\n",
    "        print('Appending year 2012...')\n",
    "        df_list.append(self.data_2012)\n",
    "\n",
    "        for year in range(2013, 2023):\n",
    "            print(f'Appending year {year}...')\n",
    "            extension = 'xlsx' if year > 2018 else 'xls'\n",
    "            df = pd.read_excel(f'data/raw/cbs/kwb-{year}.{extension}') # remove nrows later\n",
    "            df = df[self.columns_of_interest]\n",
    "            df['year'] = year\n",
    "            df_list.append(df)\n",
    "\n",
    "        self.data_all = pd.concat(df_list)\n",
    "\n",
    "    def format_data(self, columns_list):\n",
    "        df = self.data_all\n",
    "        for column in columns_list: \n",
    "            df[column] = df[column].str.strip()\n",
    "            df[column] = df[column].str.replace(',', '.', regex=False)\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "        self.data_all = df\n",
    "\n",
    "    def save_data(self): \n",
    "        file_path = 'data/processed/cbs/kwb-all.csv'\n",
    "        self.data_all.to_csv(file_path, index=False)\n",
    "        print(f'Saved data to {file_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending year 2012...\n",
      "Appending year 2013...\n",
      "Appending year 2014...\n",
      "Appending year 2015...\n",
      "Appending year 2016...\n",
      "Appending year 2017...\n",
      "Appending year 2018...\n",
      "Appending year 2019...\n",
      "Appending year 2020...\n",
      "Appending year 2021...\n",
      "Appending year 2022...\n",
      "Saved data to data/processed/cbs/kwb-all.csv\n"
     ]
    }
   ],
   "source": [
    "data_processor = CBSDataProcessor()\n",
    "data_processor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBS Spatial Data Adder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBSSpatialDataProcessor(): \n",
    "    def run(self): \n",
    "        # self.rename_zip_files()\n",
    "        self.save_buurt_data()\n",
    "        # combine buurt data with processed CBS data\n",
    "        # save combined data\n",
    "\n",
    "    def rename_zip_files(self): \n",
    "        directory = '../data/raw/cbs/wijkEnBuurtKaart'\n",
    "        year_pattern = re.compile(r'(201[2-9]|202[0-3])')\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.zip'):\n",
    "                match = year_pattern.search(filename)\n",
    "                if match:\n",
    "                    year = match.group(0)\n",
    "                    new_filename = f\"wijk_en_buurt_kaart_{year}.zip\"\n",
    "                    old_file = os.path.join(directory, filename)\n",
    "                    new_file = os.path.join(directory, new_filename)\n",
    "                    os.rename(old_file, new_file)\n",
    "    \n",
    "    def save_buurt_data(self): \n",
    "        buurt_filePaths_inZip = {}\n",
    "        for year in range(2012, 2023):\n",
    "            buurt_filePaths_inZip[year] = self._get_buurt_file_paths(year) \n",
    "            self._save_buurt_data(year, buurt_filePaths_inZip[year])\n",
    "\n",
    "    def _get_buurt_file_paths(self, year): \n",
    "        zip_file_path = f'../data/raw/cbs/wijkEnBuurtKaart/wijk_en_buurt_kaart_{year}.zip'\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_contents = zip_ref.namelist()\n",
    "            buurt_files = [filename for filename in zip_contents if 'buurt' in filename]\n",
    "            return buurt_files\n",
    "        \n",
    "    def _save_buurt_data(self, year, file_paths):\n",
    "        shp_extensions = {'.shp', '.shx', '.dbf', '.prj', '.cpg', '.sbn', '.sbx', '.xml'}\n",
    "        zip_file_path = f'../data/raw/cbs/wijkEnBuurtKaart/wijk_en_buurt_kaart_{year}.zip'\n",
    "        target_folder = f'../data/raw/cbs/wijkEnBuurtKaart/shp'\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
    "            for file_path in file_paths: \n",
    "                ext = os.path.splitext(file_path)[-1].lower()\n",
    "                if ext in shp_extensions:\n",
    "                    source = zip_file.open(file_path)\n",
    "                    new_file_name = f'buurt_{year}{ext}'\n",
    "                    target_path = os.path.join(target_folder, new_file_name)\n",
    "                    with open(target_path, 'wb') as target_file:\n",
    "                        shutil.copyfileobj(source, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2012\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[248], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2012\u001b[39m, \u001b[38;5;241m2023\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/raw/cbs/wijkEnBuurtKaart/shp/buurt_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.shp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(gdf\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/geo_env/lib/python3.9/site-packages/geopandas/io/file.py:297\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/geo_env/lib/python3.9/site-packages/geopandas/io/file.py:395\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m    392\u001b[0m         [record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m f_filt], columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    393\u001b[0m     )\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 395\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mGeoDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf_filt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m datetime_fields:\n\u001b[1;32m    399\u001b[0m     as_dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[k], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/geo_env/lib/python3.9/site-packages/geopandas/geodataframe.py:639\u001b[0m, in \u001b[0;36mGeoDataFrame.from_features\u001b[0;34m(cls, features, crs, columns)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features_lst:\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;66;03m# load geometry\u001b[39;00m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(feature, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__geo_interface__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 639\u001b[0m         feature \u001b[38;5;241m=\u001b[39m \u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__geo_interface__\u001b[49m\n\u001b[1;32m    640\u001b[0m     row \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m: shape(feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     }\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;66;03m# load properties\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/geo_env/lib/python3.9/site-packages/fiona/model.py:367\u001b[0m, in \u001b[0;36mFeature.__geo_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__geo_interface__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mObjectEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/geo_env/lib/python3.9/site-packages/fiona/model.py:388\u001b[0m, in \u001b[0;36mObjectEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, Object):\n\u001b[0;32m--> 388\u001b[0m         o_dict \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m o\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, Geometry):\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m o\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeometryCollection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/geo_env/lib/python3.9/site-packages/fiona/model.py:388\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, Object):\n\u001b[0;32m--> 388\u001b[0m         o_dict \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m o\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, Geometry):\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m o\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeometryCollection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/geo_env/lib/python3.9/site-packages/fiona/model.py:388\u001b[0m, in \u001b[0;36mObjectEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, Object):\n\u001b[0;32m--> 388\u001b[0m         o_dict \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m o\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, Geometry):\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m o\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeometryCollection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/geo_env/lib/python3.9/site-packages/fiona/model.py:388\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, Object):\n\u001b[0;32m--> 388\u001b[0m         o_dict \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m o\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, Geometry):\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m o\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeometryCollection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/geo_env/lib/python3.9/_collections_abc.py:851\u001b[0m, in \u001b[0;36mItemsView.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping:\n\u001b[0;32m--> 851\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (key, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/geo_env/lib/python3.9/site-packages/fiona/model.py:139\u001b[0m, in \u001b[0;36mObject.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m    138\u001b[0m     props \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_props()\n\u001b[0;32m--> 139\u001b[0m     props\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[item]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test if save_buurt_data works\n",
    "for year in range(2012, 2023):\n",
    "    print(f'Year: {year}')\n",
    "    gdf = gpd.read_file(f'../data/raw/cbs/wijkEnBuurtKaart/shp/buurt_{year}.shp')\n",
    "    print(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('../data/raw/cbs/wijkEnBuurtKaart/shp/buurt_2013.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBSSpatialDataProcessor().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBS Data Importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBSDataImporter(): \n",
    "    def __init__(self): \n",
    "        self.params_manager = ParamsManager()\n",
    "        self.db_name = self.params_manager.database_params['dbname']\n",
    "        self.db_user = self.params_manager.database_params['user']\n",
    "        self.db_password = self.params_manager.database_params['password']\n",
    "        self.db_host = self.params_manager.database_params['host']\n",
    "        self.db_port = self.params_manager.database_params['port']\n",
    "        self.engine = create_engine(f'postgresql://{self.db_user}:{self.db_password}@{self.db_host}:{self.db_port}/{self.db_name}')\n",
    "\n",
    "    def run(self): \n",
    "        self.import_csv_to_db()\n",
    "        # self.import_shps_to_db()\n",
    "    \n",
    "    def import_csv_to_db(self):\n",
    "        csv_file_path = 'data/processed/cbs/kwb-all.csv'\n",
    "        table_name = 'cbs_stats_all'\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        df.to_sql(table_name, self.engine, if_exists='replace', index=False)\n",
    "        print(f'Imported {csv_file_path} to {table_name} in database.')\n",
    "\n",
    "    def import_shps_to_db(self):\n",
    "        for year in range(2012, 2023): \n",
    "            shp_file_path = f'data/raw/cbs/wijkEnBuurtKaart/shp/buurt_{year}.shp'\n",
    "            table_name = f'cbs_map_{year}' \n",
    "            gdf = gpd.read_file(shp_file_path)\n",
    "            gdf.to_postgis(table_name, self.engine, if_exists='replace')\n",
    "            print(f'Imported {shp_file_path} to {table_name} in database.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tanyatsui/Documents/01_Projects/housingEmissions\n",
      "Imported data/processed/cbs/kwb-all.csv to cbs_stats_all in database.\n"
     ]
    }
   ],
   "source": [
    "CBSDataImporter().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBS Data Combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBSDataCombiner(): \n",
    "    def run(self): \n",
    "        QueryRunner('sql/create_table/cbs_map_all.sql').run_query('creating cbs_map_all table...')\n",
    "        QueryRunner('sql/data_processing/cbs/combine_cbs_maps_pre2018.sql').run_query_for_each_year(start_year=2012, end_year=2017, message='add pre-2018 cbs maps to cbs_maps_all...')\n",
    "        QueryRunner('sql/data_processing/cbs/combine_cbs_maps_post2018.sql').run_query_for_each_year(start_year=2018, end_year=2021, message='adding post-2018 cbs maps to cbs_maps_all...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating cbs_map_all table...\n",
      "Done!\n",
      "\n",
      "combining pre-2018 cbs maps...\n",
      "Processing year: 2017                         \n",
      "Done!\n",
      "\n",
      "combining post-2018 cbs maps...\n",
      "Processing year: 2021                         \n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CBSDataCombiner().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2012: 14041 rows found where g_ele is not null.\n",
      "Year 2013: 14155 rows found where g_ele is not null.\n",
      "Year 2014: 14235 rows found where g_ele is not null.\n",
      "Year 2015: 14387 rows found where g_ele is not null.\n",
      "Year 2016: 15033 rows found where g_ele is not null.\n",
      "Year 2017: 15435 rows found where g_ele is not null.\n",
      "Year 2018: 15595 rows found where g_ele is not null.\n",
      "Year 2019: 15919 rows found where g_ele is not null.\n",
      "Year 2020: 16524 rows found where g_ele is not null.\n",
      "Year 2021: 16746 rows found where g_ele is not null.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Database connection details (modify with your actual details)\n",
    "db_config = {\n",
    "    'dbname': 'urbanmining',\n",
    "    'user': 'postgres',\n",
    "    'password': 'Tunacompany5694!',\n",
    "    'host': 'localhost',  # Or your DB host\n",
    "    'port': '5432'  # Default PostgreSQL port\n",
    "}\n",
    "\n",
    "# Function to connect to the database and execute the query for a specific year\n",
    "def execute_query_for_year(year):\n",
    "    query = f''' \n",
    "    SELECT COUNT(*)\n",
    "    FROM cbs_stats_all \n",
    "    WHERE year = {year}\n",
    "    AND g_ele IS NOT NULL\n",
    "    '''\n",
    "    try:\n",
    "        # Establishing the connection\n",
    "        conn = psycopg2.connect(**db_config)\n",
    "        # Creating a cursor object\n",
    "        cur = conn.cursor()\n",
    "        # Executing the query\n",
    "        cur.execute(query)\n",
    "        # Fetching the result\n",
    "        result = cur.fetchone()[0]\n",
    "        # Printing the result\n",
    "        print(f\"Year {year}: {result} rows found where g_ele is not null.\")\n",
    "        # Closing the cursor and connection\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query for year {year}: {e}\")\n",
    "\n",
    "# Loop through each year and execute the query\n",
    "for year in range(2012, 2022):\n",
    "    execute_query_for_year(year)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
